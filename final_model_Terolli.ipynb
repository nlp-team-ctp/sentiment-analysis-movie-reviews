{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/IMDB Dataset.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='review', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    \n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize document\n",
    "    tk = RegexpTokenizer(r'[a-zA-Z\\'\\-\\_]+')\n",
    "    tokens = [token for token in tk.tokenize(document)]\n",
    "    tokens = [token for token in tokens if token != 'br']\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_review'] = df['review'].apply(preprocess)\n",
    "df.drop(['review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei's love in the time of money is a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       clean_review\n",
       "0  positive  one of the other reviewers has mentioned that ...\n",
       "1  positive  a wonderful little production the filming tech...\n",
       "2  positive  i thought this was a wonderful way to spend ti...\n",
       "3  negative  basically there's a family where a little boy ...\n",
       "4  positive  petter mattei's love in the time of money is a..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just oz episode you'll be hooked they are right as this is exactly what happened with me the first thing that struck me about oz was its brutality and unflinching scenes of violence which set in right from the word go trust me this is not a show for the faint hearted or timid this show pulls no punches with regards to drugs sex or violence its is hardcore in the classic use of the word it is called oz as that is the nickname given to the oswald maximum security state penitentary it focuses mainly on emerald city an experimental section of the prison where all the cells have glass fronts and face inwards so privacy is not high on the agenda em city is home to many aryans muslims gangstas latinos christians italians irish and more so scuffles death stares dodgy dealings and shady agreements are never far away i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare forget pretty pictures painted for mainstream audiences forget charm forget romance oz doesn't mess around the first episode i ever saw struck me as so nasty it was surreal i couldn't say i was ready for it but as i watched more i developed a taste for oz and got accustomed to the high levels of graphic violence not just violence but injustice crooked guards who'll be sold out for a nickel inmates who'll kill on order and get away with it well mannered middle class inmates being turned into prison bitches due to their lack of street skills or prison experience watching oz you may become comfortable with what is uncomfortable viewing thats if you can get in touch with your darker side\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sentiment'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df['clean_review'].tolist()\n",
    "y = df['sentiment_positive'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 9024284)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done   1 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=11)]: Done   2 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=11)]: Done   3 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=11)]: Done   4 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=11)]: Done   5 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=11)]: Done   6 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=11)]: Done   7 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=11)]: Done   8 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=11)]: Done   9 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=11)]: Done  11 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=11)]: Done  12 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=11)]: Done  13 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=11)]: Done  14 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=11)]: Done  15 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=11)]: Done  16 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=11)]: Done  17 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=11)]: Done  18 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=11)]: Done  20 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=11)]: Done  21 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=11)]: Done  22 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=11)]: Done  23 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=11)]: Done  24 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=11)]: Done  25 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  26 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  27 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=11)]: Done  29 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=11)]: Done  30 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=11)]: Done  31 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=11)]: Done  32 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=11)]: Done  33 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=11)]: Done  34 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=11)]: Done  35 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=11)]: Done  36 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=11)]: Done  37 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=11)]: Done  38 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=11)]: Done  39 tasks      | elapsed:   10.0s\n",
      "[Parallel(n_jobs=11)]: Done  40 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=11)]: Done  41 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=11)]: Done  42 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=11)]: Done  43 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=11)]: Done  44 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=11)]: Done  45 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=11)]: Done  46 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=11)]: Done  47 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=11)]: Done  48 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=11)]: Done  49 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=11)]: Done  50 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=11)]: Done  51 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=11)]: Done  52 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=11)]: Done  53 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=11)]: Done  54 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=11)]: Done  55 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=11)]: Done  56 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=11)]: Done  57 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done  58 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done  59 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done  60 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=11)]: Done  61 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=11)]: Done  62 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=11)]: Done  63 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=11)]: Done  64 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=11)]: Done  65 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=11)]: Done  66 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=11)]: Done  67 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=11)]: Done  68 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=11)]: Done  69 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=11)]: Done  70 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=11)]: Done  71 tasks      | elapsed:   17.0s\n",
      "[Parallel(n_jobs=11)]: Done  72 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=11)]: Done  73 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=11)]: Done  74 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=11)]: Done  75 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=11)]: Done  76 tasks      | elapsed:   17.6s\n",
      "[Parallel(n_jobs=11)]: Done  77 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=11)]: Done  78 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=11)]: Done  79 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=11)]: Done  81 out of 100 | elapsed:   19.2s remaining:    4.4s\n",
      "[Parallel(n_jobs=11)]: Done  83 out of 100 | elapsed:   19.4s remaining:    3.9s\n",
      "[Parallel(n_jobs=11)]: Done  85 out of 100 | elapsed:   19.5s remaining:    3.4s\n",
      "[Parallel(n_jobs=11)]: Done  87 out of 100 | elapsed:   19.8s remaining:    2.9s\n",
      "[Parallel(n_jobs=11)]: Done  89 out of 100 | elapsed:   21.0s remaining:    2.5s\n",
      "[Parallel(n_jobs=11)]: Done  91 out of 100 | elapsed:   21.2s remaining:    2.0s\n",
      "[Parallel(n_jobs=11)]: Done  93 out of 100 | elapsed:   21.5s remaining:    1.5s\n",
      "[Parallel(n_jobs=11)]: Done  95 out of 100 | elapsed:   21.6s remaining:    1.0s\n",
      "[Parallel(n_jobs=11)]: Done  97 out of 100 | elapsed:   21.7s remaining:    0.6s\n",
      "[Parallel(n_jobs=11)]: Done 100 out of 100 | elapsed:   22.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=MultinomialNB(), n_jobs=11,\n",
       "                   param_distributions={'alpha': array([0.        , 0.01010101, 0.02020202, 0.03030303, 0.04040404,\n",
       "       0.05050505, 0.06060606, 0.07070707, 0.08080808, 0.09090909,\n",
       "       0.1010101 , 0.11111111, 0.12121212, 0.13131313, 0.14141414,\n",
       "       0.15151515, 0.16161616, 0.17171717, 0.18181818, 0.19191919,\n",
       "       0.2020202 , 0.21212121, 0.22222222, 0.23232323...\n",
       "       0.65656566, 0.66666667, 0.67676768, 0.68686869, 0.6969697 ,\n",
       "       0.70707071, 0.71717172, 0.72727273, 0.73737374, 0.74747475,\n",
       "       0.75757576, 0.76767677, 0.77777778, 0.78787879, 0.7979798 ,\n",
       "       0.80808081, 0.81818182, 0.82828283, 0.83838384, 0.84848485,\n",
       "       0.85858586, 0.86868687, 0.87878788, 0.88888889, 0.8989899 ,\n",
       "       0.90909091, 0.91919192, 0.92929293, 0.93939394, 0.94949495,\n",
       "       0.95959596, 0.96969697, 0.97979798, 0.98989899, 1.        ])},\n",
       "                   verbose=100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "distributions = {'alpha': np.linspace(0,1,100)}\n",
    "clf = RandomizedSearchCV(model, distributions, cv=10, verbose=100, n_jobs=11)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9011974228636885\n",
      "0.9007764444892609\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.23232323232323235}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('models/MultiNB_model_90_accu.pkl', 'wb'))\n",
    "pickle.dump(vectorizer, open('models/trigram_vectorizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX ACCURACY: 90.6% \n",
    "# MODEL AND VECTORIZER TO BIG TO PUSH TO GITHUB\n",
    "\n",
    "# document = document.lower()\n",
    "# tk = RegexpTokenizer(r'[a-zA-Z\\'\\-\\_]+')\n",
    "# tokens = [token for token in tk.tokenize(document)]\n",
    "# tokens = [token for token in tokens if token != 'br']\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(1,4))\n",
    "\n",
    "# model = MultinomialNB()\n",
    "# distributions = {'alpha': np.linspace(0,1,100)}\n",
    "# clf = RandomizedSearchCV(model, distributions, cv=10, verbose=100, n_jobs=11)\n",
    "# clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
