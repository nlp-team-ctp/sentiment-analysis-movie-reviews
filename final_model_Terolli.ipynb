{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/IMDB Dataset.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review       0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='review', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    \n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize document\n",
    "    tk = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    tokens = [token for token in tk.tokenize(document)]\n",
    "    tokens = [token for token in tokens if token != 'br']\n",
    "\n",
    "    # remove stop words\n",
    "    tokens = [token for token in tokens if token not in stopwords]\n",
    "\n",
    "    # stemmer\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "\n",
    "    # remove words with length 1\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_review'] = df['review'].apply(preprocess)\n",
    "df.drop(['review'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>one review mention watch oz episod hook right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>basic famili littl boy jake think zombi closet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       clean_review\n",
       "0  positive  one review mention watch oz episod hook right ...\n",
       "1  positive  wonder littl product film techniqu unassum old...\n",
       "2  positive  thought wonder way spend time hot summer weeke...\n",
       "3  negative  basic famili littl boy jake think zombi closet...\n",
       "4  positive  petter mattei love time money visual stun film..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one review mention watch oz episod hook right exactli happen first thing struck oz brutal unflinch scene violenc set right word go trust show faint heart timid show pull punch regard drug sex violenc hardcor classic use word call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far away would say main appeal show due fact goe show dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz mess around first episod ever saw struck nasti surreal say readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view that get touch darker side'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sentiment'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df['clean_review'].tolist()\n",
    "y = df['sentiment_positive'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49582, 7908403)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n",
      "[Parallel(n_jobs=11)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done   1 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=11)]: Done   2 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=11)]: Done   3 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=11)]: Done   4 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=11)]: Done   5 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=11)]: Done   6 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=11)]: Done   7 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=11)]: Done   8 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=11)]: Done   9 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=11)]: Done  10 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=11)]: Done  11 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=11)]: Done  12 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=11)]: Done  13 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=11)]: Done  14 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=11)]: Done  15 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=11)]: Done  16 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=11)]: Done  17 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=11)]: Done  18 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=11)]: Done  19 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=11)]: Done  20 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=11)]: Done  21 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=11)]: Done  22 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=11)]: Done  23 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=11)]: Done  24 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=11)]: Done  25 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=11)]: Done  26 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=11)]: Done  27 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=11)]: Done  29 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=11)]: Done  30 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=11)]: Done  31 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=11)]: Done  32 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=11)]: Done  33 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=11)]: Done  34 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=11)]: Done  35 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=11)]: Done  36 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=11)]: Done  37 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=11)]: Done  38 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  39 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  40 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=11)]: Done  41 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=11)]: Done  42 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=11)]: Done  43 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=11)]: Done  44 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=11)]: Done  45 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=11)]: Done  46 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=11)]: Done  47 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=11)]: Done  48 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=11)]: Done  49 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=11)]: Done  50 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=11)]: Done  51 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=11)]: Done  52 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=11)]: Done  53 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=11)]: Done  54 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=11)]: Done  55 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=11)]: Done  56 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=11)]: Done  57 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=11)]: Done  58 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=11)]: Done  59 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=11)]: Done  60 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=11)]: Done  61 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=11)]: Done  62 tasks      | elapsed:   11.1s\n",
      "[Parallel(n_jobs=11)]: Done  63 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=11)]: Done  64 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=11)]: Done  65 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=11)]: Done  66 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=11)]: Done  67 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=11)]: Done  68 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=11)]: Done  69 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=11)]: Done  70 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=11)]: Done  71 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=11)]: Done  72 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=11)]: Done  73 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=11)]: Done  74 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=11)]: Done  75 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=11)]: Done  76 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=11)]: Done  77 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=11)]: Done  78 tasks      | elapsed:   13.9s\n",
      "[Parallel(n_jobs=11)]: Done  79 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=11)]: Done  80 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=11)]: Done  81 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=11)]: Done  82 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=11)]: Done  83 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=11)]: Done  84 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done  85 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=11)]: Done  86 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=11)]: Done  87 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=11)]: Done  88 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=11)]: Done  89 tasks      | elapsed:   15.5s\n",
      "[Parallel(n_jobs=11)]: Done  90 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=11)]: Done  91 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=11)]: Done  92 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=11)]: Done  93 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=11)]: Done  94 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=11)]: Done  95 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=11)]: Done  96 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=11)]: Done  97 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=11)]: Done  98 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=11)]: Done  99 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=11)]: Done 100 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=11)]: Done 101 tasks      | elapsed:   17.2s\n",
      "[Parallel(n_jobs=11)]: Done 102 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=11)]: Done 103 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=11)]: Done 104 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=11)]: Done 105 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=11)]: Done 106 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=11)]: Done 107 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=11)]: Done 108 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=11)]: Done 109 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=11)]: Done 110 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=11)]: Done 111 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=11)]: Done 112 tasks      | elapsed:   18.8s\n",
      "[Parallel(n_jobs=11)]: Done 113 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=11)]: Done 114 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=11)]: Done 115 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=11)]: Done 116 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=11)]: Done 117 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=11)]: Done 118 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=11)]: Done 119 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=11)]: Done 120 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=11)]: Done 121 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=11)]: Done 122 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=11)]: Done 123 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=11)]: Done 124 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=11)]: Done 125 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=11)]: Done 126 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=11)]: Done 127 tasks      | elapsed:   20.8s\n",
      "[Parallel(n_jobs=11)]: Done 128 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=11)]: Done 129 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=11)]: Done 131 out of 150 | elapsed:   21.3s remaining:    3.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done 133 out of 150 | elapsed:   21.9s remaining:    2.7s\n",
      "[Parallel(n_jobs=11)]: Done 135 out of 150 | elapsed:   22.3s remaining:    2.4s\n",
      "[Parallel(n_jobs=11)]: Done 137 out of 150 | elapsed:   22.4s remaining:    2.0s\n",
      "[Parallel(n_jobs=11)]: Done 139 out of 150 | elapsed:   22.5s remaining:    1.7s\n",
      "[Parallel(n_jobs=11)]: Done 141 out of 150 | elapsed:   22.8s remaining:    1.4s\n",
      "[Parallel(n_jobs=11)]: Done 143 out of 150 | elapsed:   23.0s remaining:    1.0s\n",
      "[Parallel(n_jobs=11)]: Done 145 out of 150 | elapsed:   23.5s remaining:    0.7s\n",
      "[Parallel(n_jobs=11)]: Done 147 out of 150 | elapsed:   23.7s remaining:    0.4s\n",
      "[Parallel(n_jobs=11)]: Done 150 out of 150 | elapsed:   23.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=15, estimator=MultinomialNB(), n_jobs=11,\n",
       "                   param_distributions={'alpha': array([0.        , 0.01010101, 0.02020202, 0.03030303, 0.04040404,\n",
       "       0.05050505, 0.06060606, 0.07070707, 0.08080808, 0.09090909,\n",
       "       0.1010101 , 0.11111111, 0.12121212, 0.13131313, 0.14141414,\n",
       "       0.15151515, 0.16161616, 0.17171717, 0.18181818, 0.19191919,\n",
       "       0.2020202 , 0.21212121, 0.22222222, 0.23232323...\n",
       "       0.65656566, 0.66666667, 0.67676768, 0.68686869, 0.6969697 ,\n",
       "       0.70707071, 0.71717172, 0.72727273, 0.73737374, 0.74747475,\n",
       "       0.75757576, 0.76767677, 0.77777778, 0.78787879, 0.7979798 ,\n",
       "       0.80808081, 0.81818182, 0.82828283, 0.83838384, 0.84848485,\n",
       "       0.85858586, 0.86868687, 0.87878788, 0.88888889, 0.8989899 ,\n",
       "       0.90909091, 0.91919192, 0.92929293, 0.93939394, 0.94949495,\n",
       "       0.95959596, 0.96969697, 0.97979798, 0.98989899, 1.        ])},\n",
       "                   verbose=100)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "distributions = {'alpha': np.linspace(0,1,100)}\n",
    "clf = RandomizedSearchCV(model, distributions, cv=15, verbose=100, n_jobs=11)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8905333234191956\n",
      "0.8883735000504185\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_score_)\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.23232323232323235}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model, open('MultiNB_model_89_accu.pkl', 'wb'))\n",
    "pickle.dump(vectorizer, open('trigram_vectorizer.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
