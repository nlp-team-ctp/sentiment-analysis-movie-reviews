{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import logging\n",
    "import nltk\n",
    "from gensim import corpora, utils\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from smart_open import open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize document\n",
    "    tk = RegexpTokenizer(r'[a-zA-Z\\'\\-\\_]+')\n",
    "    tokens = [token for token in tk.tokenize(document)]\n",
    "    tokens = [token for token in tokens if token != 'br']\n",
    "\n",
    "    # determine stop words\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    # remove stop words\n",
    "    tokens = [token for token in tokens if token not in stoplist]\n",
    "\n",
    "    # stemmer\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "\n",
    "    # remove words with length 1\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('..\\data\\IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df['clean_review'] = df['review'].apply(preprocess)\n",
    "\n",
    "\n",
    "X = df['clean_review'].tolist()\n",
    "y = df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120253"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = Dictionary(X)\n",
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28564"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.filter_extremes(no_below=5, no_above=0.6)\n",
    "len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dct.doc2bow(doc) for doc in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct.save('dictionary.dict')\n",
    "corpora.MmCorpus.serialize('mycorpus.mm', corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
