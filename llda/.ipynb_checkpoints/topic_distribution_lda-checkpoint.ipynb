{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from smart_open import open\n",
    "from gensim import corpora, utils\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-18 15:19:52,197 : INFO : loading Dictionary object from dictionary.dict\n",
      "2020-11-18 15:19:52,198 : DEBUG : {'uri': 'dictionary.dict', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,219 : INFO : loaded dictionary.dict\n",
      "2020-11-18 15:19:52,220 : INFO : loading LdaMulticore object from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model\n",
      "2020-11-18 15:19:52,220 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,221 : INFO : loading expElogbeta from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.expElogbeta.npy with mmap=None\n",
      "2020-11-18 15:19:52,229 : INFO : setting ignored attribute state to None\n",
      "2020-11-18 15:19:52,230 : INFO : setting ignored attribute dispatcher to None\n",
      "2020-11-18 15:19:52,230 : INFO : setting ignored attribute id2word to None\n",
      "2020-11-18 15:19:52,231 : INFO : loaded C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model\n",
      "2020-11-18 15:19:52,231 : INFO : loading LdaState object from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.state\n",
      "2020-11-18 15:19:52,231 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model.state', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,272 : INFO : loaded C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.state\n",
      "2020-11-18 15:19:52,273 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model.id2word', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    }
   ],
   "source": [
    "# load dictionary\n",
    "dct = corpora.Dictionary.load('dictionary.dict')\n",
    "\n",
    "# load model\n",
    "lda = LdaMulticore.load(datapath('lda_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize document\n",
    "    tk = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    tokens = [token for token in tk.tokenize(document)]\n",
    "    tokens = [token for token in tokens if token != 'br']\n",
    "\n",
    "    # determine stop words\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    # remove stop words\n",
    "    tokens = [token for token in tokens if token not in stoplist]\n",
    "\n",
    "    # stemmer\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "\n",
    "    # remove words with length 1\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"C:\\\\Users\\\\Terolli\\\\Desktop\\\\sentiment-analysis-movie-reviews\\\\llda\\\\IMDB Dataset.csv\")\n",
    "df = df.drop_duplicates()\n",
    "df['clean_review'] = df['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].tolist()\n",
    "\n",
    "X = df['clean_review'].tolist()\n",
    "y = df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(68996 unique tokens: ['accustom', 'agenda', 'agreement', 'appeal', 'around']...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dct)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This short film that inspired the soon-to-be full length feature - Spatula Madness - is a hilarious piece that contends against similar cartoons yielding multiple writers. The short film stars Edward the Spatula who after being fired from his job, joins in the fight against the evil spoons. This premise allows for some funny content near the beginning, but is barely present for the remainder of the feature. This film's 15-minute running time is absorbed by some odd-ball comedy and a small musical number. Unfortunately not much else lies below it. The plot that is set up doesn't really have time to show. But it's surely follows it plot better than many high-budget Hollywood films. This film is worth watching at least a few times. Take it for what it is, and don't expect a deep story.\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "X_test_corpus = dct.doc2bow(X[100])\n",
    "print(reviews[100])\n",
    "print(y[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(71, 0.7810817), (17, 0.114477724), (27, 0.091832176)]\n"
     ]
    }
   ],
   "source": [
    "# topic probability distribution of unseen document\n",
    "vector = lda[X_test_corpus]\n",
    "vector.sort(key = lambda tup: tup[1], reverse=True)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     word  probability\n",
      "0    film     0.031236\n",
      "1     one     0.009177\n",
      "2    movi     0.007480\n",
      "3    like     0.006537\n",
      "4  horror     0.006221\n",
      "5    look     0.005731\n",
      "6    make     0.005664\n",
      "7   scene     0.005532\n",
      "8    plot     0.005263\n",
      "9    good     0.005164\n",
      "\n",
      "      word  probability\n",
      "0     danc     0.042316\n",
      "1    music     0.030529\n",
      "2    kelli     0.017657\n",
      "3     sing     0.016779\n",
      "4     song     0.014599\n",
      "5   number     0.014367\n",
      "6  cartoon     0.012870\n",
      "7      cat     0.012810\n",
      "8    jerri     0.010733\n",
      "9  sinatra     0.009390\n",
      "\n",
      "     word  probability\n",
      "0    show     0.071591\n",
      "1    like     0.018460\n",
      "2   watch     0.014236\n",
      "3   funni     0.009991\n",
      "4     one     0.009176\n",
      "5    time     0.009123\n",
      "6      tv     0.009071\n",
      "7  episod     0.008236\n",
      "8   great     0.007751\n",
      "9    love     0.007412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in vector:\n",
    "    top_terms_id = lda.get_topic_terms(topic[0])\n",
    "    top_terms_word = [(lda.id2word[id], prob) for id, prob in top_terms_id]\n",
    "\n",
    "    df2 = pd.DataFrame(top_terms_word, columns =['word', 'probability'])\n",
    "    print(df2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# getting topic id with highest probability\n",
    "top_topic = max(vector, key=lambda x:x[1])\n",
    "print(top_topic)\n",
    "\n",
    "# getting word representation of topic\n",
    "top_terms_id = lda.get_topic_terms(top_topic[0])\n",
    "print(top_terms_id)\n",
    "\n",
    "# converting ids to words\n",
    "top_terms_word = [(lda.id2word[id], prob) for id, prob in top_terms_id]\n",
    "\n",
    "df2 = pd.DataFrame(top_terms_word, columns =['word', 'probability'])\n",
    "df2\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
