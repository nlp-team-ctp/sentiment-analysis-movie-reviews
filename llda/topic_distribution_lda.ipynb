{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import gensim\n",
    "from collections import defaultdict\n",
    "from smart_open import open\n",
    "from gensim import corpora, utils\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import PlaintextCorpusReader, stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.setLevel(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-18 15:19:52,197 : INFO : loading Dictionary object from dictionary.dict\n",
      "2020-11-18 15:19:52,198 : DEBUG : {'uri': 'dictionary.dict', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,219 : INFO : loaded dictionary.dict\n",
      "2020-11-18 15:19:52,220 : INFO : loading LdaMulticore object from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model\n",
      "2020-11-18 15:19:52,220 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,221 : INFO : loading expElogbeta from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.expElogbeta.npy with mmap=None\n",
      "2020-11-18 15:19:52,229 : INFO : setting ignored attribute state to None\n",
      "2020-11-18 15:19:52,230 : INFO : setting ignored attribute dispatcher to None\n",
      "2020-11-18 15:19:52,230 : INFO : setting ignored attribute id2word to None\n",
      "2020-11-18 15:19:52,231 : INFO : loaded C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model\n",
      "2020-11-18 15:19:52,231 : INFO : loading LdaState object from C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.state\n",
      "2020-11-18 15:19:52,231 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model.state', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n",
      "2020-11-18 15:19:52,272 : INFO : loaded C:\\Users\\Terolli\\anaconda3\\lib\\site-packages\\gensim\\test\\test_data\\lda_model.state\n",
      "2020-11-18 15:19:52,273 : DEBUG : {'uri': 'C:\\\\Users\\\\Terolli\\\\anaconda3\\\\lib\\\\site-packages\\\\gensim\\\\test\\\\test_data\\\\lda_model.id2word', 'mode': 'rb', 'buffering': -1, 'encoding': None, 'errors': None, 'newline': None, 'closefd': True, 'opener': None, 'ignore_ext': False, 'transport_params': None}\n"
     ]
    }
   ],
   "source": [
    "# load dictionary\n",
    "dct = corpora.Dictionary.load('dictionary.dict')\n",
    "\n",
    "# load model\n",
    "lda = LdaMulticore.load(datapath('lda_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(document):\n",
    "    # convert to lower case\n",
    "    document = document.lower()\n",
    "\n",
    "    # tokenize document\n",
    "    tk = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    tokens = [token for token in tk.tokenize(document)]\n",
    "    tokens = [token for token in tokens if token != 'br']\n",
    "\n",
    "    # determine stop words\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    # remove stop words\n",
    "    tokens = [token for token in tokens if token not in stoplist]\n",
    "\n",
    "    # stemmer\n",
    "    porter = PorterStemmer()\n",
    "    tokens = [porter.stem(token) for token in tokens]\n",
    "\n",
    "    # remove words with length 1\n",
    "    tokens = [token for token in tokens if len(token) > 1]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IMDB Dataset.csv')\n",
    "df = df.drop_duplicates()\n",
    "df['clean_review'] = df['review'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df['review'].tolist()\n",
    "\n",
    "X = df['clean_review'].tolist()\n",
    "y = df['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(68996 unique tokens: ['accustom', 'agenda', 'agreement', 'appeal', 'around']...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49582"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dct)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_number = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah yes the 1980s , a time of Reaganomics and Sly , Chuck and a host of other action stars hiding in a remote jungle blowing away commies . At the time I couldn`t believe how movies like RAMBO , MISSING IN ACTION and UNCOMMON VALOR ( And who can forget the ridiculous RED DAWN ? ) made money at the box office , they`re turgid action crap fests with a rather off putting right wing agenda and they have dated very badly . TROMA`S WAR is a tongue in cheek take on these type of movies but you`ve got to ask yourself did they need spoofing in the first place ? Of course not . TROMA`S WAR lacks any sort of sophistication - though it does make the point that there`s no real difference between right wing tyrants and left wing ones - and sometimes feels more like a grade z movie than a send up . Maybe it is ?\n",
      "\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "X_test_corpus = dct.doc2bow(X[doc_number])\n",
    "print(reviews[doc_number])\n",
    "print()\n",
    "print(y[doc_number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(33, 0.38143355), (12, 0.35148922), (65, 0.101080865), (43, 0.08851358), (56, 0.035207417), (6, 0.030651374)]\n"
     ]
    }
   ],
   "source": [
    "# topic probability distribution of unseen document\n",
    "vector = lda[X_test_corpus]\n",
    "vector.sort(key = lambda tup: tup[1], reverse=True)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(33, 0.38143355), (12, 0.35148922), (65, 0.101080865)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = [tup for tup in vector if tup[1] >= 0.1]\n",
    "print(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     WORD  PROBABILITY\n",
      "0    film     0.013625\n",
      "1     one     0.013470\n",
      "2    like     0.006132\n",
      "3    time     0.006012\n",
      "4    movi     0.005167\n",
      "5   scene     0.004627\n",
      "6     get     0.004366\n",
      "7  keaton     0.004163\n",
      "8    play     0.003813\n",
      "9    take     0.003535\n",
      "\n",
      "     WORD  PROBABILITY\n",
      "0    movi     0.066134\n",
      "1    like     0.014655\n",
      "2   watch     0.014458\n",
      "3     one     0.013850\n",
      "4     bad     0.011245\n",
      "5    good     0.010090\n",
      "6  realli     0.009346\n",
      "7    time     0.009193\n",
      "8     see     0.008894\n",
      "9    make     0.008801\n",
      "\n",
      "       WORD  PROBABILITY\n",
      "0       war     0.028516\n",
      "1   soldier     0.013621\n",
      "2       one     0.008126\n",
      "3   russian     0.006540\n",
      "4  militari     0.006310\n",
      "5     world     0.006218\n",
      "6      film     0.006209\n",
      "7      armi     0.006153\n",
      "8      movi     0.004372\n",
      "9       man     0.004098\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in top_topics:\n",
    "    top_terms_id = lda.get_topic_terms(topic[0])\n",
    "    top_terms_word = [(lda.id2word[id], prob) for id, prob in top_terms_id]\n",
    "\n",
    "    df2 = pd.DataFrame(top_terms_word, columns =['WORD', 'PROBABILITY'])\n",
    "    print(df2)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# getting topic id with highest probability\n",
    "top_topic = max(vector, key=lambda x:x[1])\n",
    "print(top_topic)\n",
    "\n",
    "# getting word representation of topic\n",
    "top_terms_id = lda.get_topic_terms(top_topic[0])\n",
    "print(top_terms_id)\n",
    "\n",
    "# converting ids to words\n",
    "top_terms_word = [(lda.id2word[id], prob) for id, prob in top_terms_id]\n",
    "\n",
    "df2 = pd.DataFrame(top_terms_word, columns =['word', 'probability'])\n",
    "df2\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
